{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wYfViVSz2s-"
      },
      "source": [
        "# XLM-Roberta Named Entity Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQfLZ9cJz_7i"
      },
      "source": [
        "## How to start "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gF9_1lkWzu3j"
      },
      "outputs": [],
      "source": [
        "# Optional: You can mount google drive to save your checkpoints in it: \n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f3ZMtEh6g3le"
      },
      "outputs": [],
      "source": [
        "# Optional: remove previous files if you want to run it again without any problem \n",
        "\n",
        "# ! rm -rf drive\n",
        "# ! rm -rf model\n",
        "# ! rm -rf sample_data\n",
        "\n",
        "\n",
        "# Remove data folder if already exists\n",
        "! rm -rf data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmK6V-wGzx7R"
      },
      "source": [
        "### Paths and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FqaswDc55pGu"
      },
      "outputs": [],
      "source": [
        "DEBUG = False # Debug mode: If True then training set will be limited to MAX_EXAMPLES\n",
        "MAX_EXAMPLES = 1000 # Size of Debug Set\n",
        "MAX_EPOCHS = 15 # Max Number of epoochs \n",
        "CHECKPOINT_PATH = \"./drive/MyDrive\" # Root directory of checkpoints \n",
        "MODEL_PATH = \"./model\" # Root directory of pytorch model\n",
        "MODEL_NAME = \"model.pt\" # name of final pytorch model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OqhHJAQNYiq"
      },
      "source": [
        "### Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hKV8xJFzHtyI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "10ce31d5-e30c-4d57-b20c-b05ab01d488a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.5.9-py3-none-any.whl (527 kB)\n",
            "\u001b[K     |████████████████████████████████| 527 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.7.0)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 30.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 43.6 MB/s \n",
            "\u001b[?25hCollecting setuptools==59.5.0\n",
            "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "\u001b[K     |████████████████████████████████| 952 kB 37.7 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.7.0-py3-none-any.whl (396 kB)\n",
            "\u001b[K     |████████████████████████████████| 396 kB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (3.10.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.3)\n",
            "Collecting PyYAML>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 36.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.7)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.43.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.4.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 32.6 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.11)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 36.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=1f7a74b33d83eb61ac567f08bde9b3ae6581b91bca859846a4d7cfb547e4caf4\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built future\n",
            "Installing collected packages: setuptools, multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyDeprecate, fsspec, aiohttp, torchmetrics, PyYAML, future, pytorch-lightning\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.1.0 future-0.18.2 multidict-6.0.2 pyDeprecate-0.3.1 pytorch-lightning-1.5.9 setuptools-59.5.0 torchmetrics-0.7.0 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-crf\n",
            "  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 43.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 31.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.4.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.2\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=ef5868a373a45302597054b6cc246eb04b7a117d324e10f0f45ce125790a7af9\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.62.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.4.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install pytorch-lightning \n",
        "! pip install pytorch-crf # Crf layer\n",
        "! pip install transformers\n",
        "! pip install seqeval # Evaluation\n",
        "! pip install gdown # Downlowd from google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dm774ZtCsYZd"
      },
      "outputs": [],
      "source": [
        "# ! gdown --id ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1ZrHrYJNeja"
      },
      "source": [
        "### Download Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1siw22dvPiVg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "711a678e-026b-41f2-9d17-d733bf9ea0f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-01 20:15:59--  https://github.com/language-ml/4-token-classification/raw/main/Multilingual-NER/en_test.csv\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/language-ml/4-token-classification/main/Multilingual-NER/en_test.csv [following]\n",
            "--2022-02-01 20:15:59--  https://raw.githubusercontent.com/language-ml/4-token-classification/main/Multilingual-NER/en_test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 219239 (214K) [text/plain]\n",
            "Saving to: ‘./data/en_test.csv’\n",
            "\n",
            "en_test.csv         100%[===================>] 214.10K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-02-01 20:15:59 (8.78 MB/s) - ‘./data/en_test.csv’ saved [219239/219239]\n",
            "\n",
            "--2022-02-01 20:15:59--  https://github.com/language-ml/4-token-classification/raw/main/Multilingual-NER/en_train.csv\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/language-ml/4-token-classification/main/Multilingual-NER/en_train.csv [following]\n",
            "--2022-02-01 20:15:59--  https://raw.githubusercontent.com/language-ml/4-token-classification/main/Multilingual-NER/en_train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5223045 (5.0M) [text/plain]\n",
            "Saving to: ‘./data/en_train.csv’\n",
            "\n",
            "en_train.csv        100%[===================>]   4.98M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-02-01 20:16:00 (69.1 MB/s) - ‘./data/en_train.csv’ saved [5223045/5223045]\n",
            "\n",
            "--2022-02-01 20:16:00--  https://github.com/language-ml/4-token-classification/raw/main/Multilingual-NER/fa_test.csv\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/language-ml/4-token-classification/main/Multilingual-NER/fa_test.csv [following]\n",
            "--2022-02-01 20:16:00--  https://raw.githubusercontent.com/language-ml/4-token-classification/main/Multilingual-NER/fa_test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 276991 (270K) [text/plain]\n",
            "Saving to: ‘./data/fa_test.csv’\n",
            "\n",
            "fa_test.csv         100%[===================>] 270.50K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-02-01 20:16:00 (8.79 MB/s) - ‘./data/fa_test.csv’ saved [276991/276991]\n",
            "\n",
            "--2022-02-01 20:16:00--  https://github.com/language-ml/4-token-classification/raw/main/Multilingual-NER/fa_train.csv\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/language-ml/4-token-classification/main/Multilingual-NER/fa_train.csv [following]\n",
            "--2022-02-01 20:16:01--  https://raw.githubusercontent.com/language-ml/4-token-classification/main/Multilingual-NER/fa_train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6392678 (6.1M) [text/plain]\n",
            "Saving to: ‘./data/fa_train.csv’\n",
            "\n",
            "fa_train.csv        100%[===================>]   6.10M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2022-02-01 20:16:01 (77.8 MB/s) - ‘./data/fa_train.csv’ saved [6392678/6392678]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create data folder and donwload required datasets\n",
        "! mkdir data\n",
        "! wget https://github.com/language-ml/4-token-classification/raw/main/Multilingual-NER/en_test.csv -P ./data\n",
        "! wget https://github.com/language-ml/4-token-classification/raw/main/Multilingual-NER/en_train.csv -P ./data\n",
        "! wget https://github.com/language-ml/4-token-classification/raw/main/Multilingual-NER/fa_test.csv -P ./data\n",
        "! wget https://github.com/language-ml/4-token-classification/raw/main/Multilingual-NER/fa_train.csv -P ./data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiFCEopXNmRp"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l35D2afgGuxg"
      },
      "outputs": [],
      "source": [
        "# import primitive libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# import seqval to report classifier performance metrics\n",
        "from seqeval.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from seqeval.scheme import IOB2\n",
        "\n",
        "# import torch related modules\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn as nn\n",
        "\n",
        "# import pytorch lightning library\n",
        "import pytorch_lightning as pl\n",
        "from torchcrf import CRF as SUPERCRF\n",
        "\n",
        "# import NLTK to create better tokenizer\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "# Transformers : Roberta Model\n",
        "from transformers import XLMRobertaTokenizerFast\n",
        "from transformers import XLMRobertaModel, XLMRobertaConfig\n",
        "\n",
        "# import sklearn inorder to split data into train-evaluation-test\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "# import Typings\n",
        "from typing import Union,Dict,List,Tuple,Any,Optional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJujx4BAUcdY",
        "outputId": "fd26014a-1d77-4f9a-a6e2-303f726afdd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# for sent tokenizer (nltk)\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCIfTAhwPx8z"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jUxaxRZxvulg"
      },
      "outputs": [],
      "source": [
        "# A function to load dataset into dataframe\n",
        "def load_data(name, path='./data', test=False):\n",
        "    print(f'Processing {name}')\n",
        "    # Read CSV\n",
        "    df = pd.read_csv(path + '/' + name)\n",
        "    # Define columns\n",
        "    df.columns = ['index', 'Token', 'Tag']\n",
        "    df.set_index('index', drop=True, inplace=True)\n",
        "    # Remove rows which starts with # id\n",
        "    mask = df.Token.str.startswith('# id')\n",
        "    indices = list(map(lambda x:x+1, df.index[mask].tolist())) + [df.index[-1]]\n",
        "    # Assign Sent number to each row\n",
        "    sentence = 0\n",
        "    df['Sent'] = None\n",
        "    for index in tqdm(range(len(indices)-1)):\n",
        "        df.loc[indices[index]:indices[index+1], 'Sent'] = sentence\n",
        "        sentence += 1\n",
        "    df.drop(df.index[mask], inplace=True)\n",
        "    # Drop Tag column if Dataframe is for test\n",
        "    if test:\n",
        "      df.drop(columns='Tag', inplace=True)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjIfiWc9whCR",
        "outputId": "623d476b-3af9-4799-c9a7-0932ea010ad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing en_train.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15300/15300 [01:20<00:00, 190.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing en_test.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:00<00:00, 1477.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing fa_train.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15300/15300 [01:17<00:00, 197.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing fa_test.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:00<00:00, 1328.52it/s]\n"
          ]
        }
      ],
      "source": [
        "# EN Data\n",
        "en_data = load_data('en_train.csv')\n",
        "# clean tag column\n",
        "en_data['Tag'] = en_data['Tag'].apply(lambda tag: tag.strip() if tag!=' _ O' else 'O')\n",
        "# clean Token column\n",
        "en_data['Token'] = en_data['Token'].apply(lambda token: token.strip())\n",
        "\n",
        "# EN Test (Deploy)\n",
        "en_deploy_test = load_data('en_test.csv', test=True)\n",
        "\n",
        "# FA Data \n",
        "fa_data = load_data('fa_train.csv')\n",
        "# clean tag column\n",
        "fa_data['Tag'] = fa_data['Tag'].apply(lambda tag: tag.strip() if tag!=' _ O' else 'O')\n",
        "# clean Token column\n",
        "fa_data['Token'] = fa_data['Token'].apply(lambda token: token.strip())\n",
        "\n",
        "# FA TEST (Desploy)\n",
        "fa_deploy_test = load_data('fa_test.csv', test=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YOmxwy3mSqAk"
      },
      "outputs": [],
      "source": [
        "# Debug mode in order to reduce time consumption.\n",
        "if DEBUG ==  True:\n",
        "    en_data = en_data[:MAX_EXAMPLES]\n",
        "    fa_data = fa_data[:MAX_EXAMPLES]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "D9qkMmy3SZvS"
      },
      "outputs": [],
      "source": [
        "# Ratio of Val+Test to Training set\n",
        "VAL_TEST_SIZE = 0.3\n",
        "# Ratio of Test to Val set\n",
        "TEST_SIZE = 0.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDP18J8ZSXWE"
      },
      "source": [
        "### EN Dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "S-SZ2iUzwhqX"
      },
      "outputs": [],
      "source": [
        "# Split Dataframe into Train and Val+Test\n",
        "splitter = GroupShuffleSplit(test_size=VAL_TEST_SIZE, n_splits=1,  random_state = 42)\n",
        "split = splitter.split(en_data, groups=en_data['Sent'])\n",
        "en_train_inds, en_val_test_inds = next(split)\n",
        "\n",
        "# En Train and Val+Test\n",
        "en_train = en_data.iloc[en_train_inds]\n",
        "en_val_test = en_data.iloc[en_val_test_inds]\n",
        "\n",
        "# Split Dataframe into Val and Test\n",
        "splitter = GroupShuffleSplit(test_size=TEST_SIZE, n_splits=1,  random_state = 42)\n",
        "split = splitter.split(en_val_test, groups=en_val_test['Sent'])\n",
        "en_val_inds, en_test_inds = next(split)\n",
        "\n",
        "# En Val and Test\n",
        "en_val = en_val_test.iloc[en_val_inds]\n",
        "en_test = en_val_test.iloc[en_test_inds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "e_xVTTkmSwRn",
        "outputId": "c8a0f229-6a13-402e-cc1b-63e6d0366384"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-59416010-aace-4a38-beea-01f71fddded0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Token</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Sent</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>it</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>is</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>a</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>series</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59416010-aace-4a38-beea-01f71fddded0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59416010-aace-4a38-beea-01f71fddded0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59416010-aace-4a38-beea-01f71fddded0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        Token Tag Sent\n",
              "index                 \n",
              "16         it   O    1\n",
              "17         is   O    1\n",
              "18          a   O    1\n",
              "19     series   O    1\n",
              "20         of   O    1"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "en_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iipkxa5LSqi7"
      },
      "source": [
        "### FA Dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2i9pgdesw_TP"
      },
      "outputs": [],
      "source": [
        "# Split Dataframe into Train and Val+Test\n",
        "splitter = GroupShuffleSplit(test_size=VAL_TEST_SIZE, n_splits=2,  random_state = 42)\n",
        "split = splitter.split(fa_data, groups=fa_data['Sent'])\n",
        "fa_train_inds, fa_val_test_inds = next(split)\n",
        "\n",
        "# FA Train and Val+Test\n",
        "fa_train = fa_data.iloc[fa_train_inds]\n",
        "fa_val_test = fa_data.iloc[fa_val_test_inds]\n",
        "\n",
        "# Split Dataframe into Val and Test\n",
        "splitter = GroupShuffleSplit(test_size=TEST_SIZE, n_splits=2,  random_state = 42)\n",
        "split = splitter.split(fa_val_test, groups=fa_val_test['Sent'])\n",
        "fa_val_inds, fa_test_inds = next(split)\n",
        "\n",
        "# FA Val and Test\n",
        "fa_val = fa_val_test.iloc[fa_val_inds]\n",
        "fa_test = fa_val_test.iloc[fa_test_inds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "oqVIAT5saHSG",
        "outputId": "2e0d5a54-651f-4671-8354-a7635dc463f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-32880d50-19e5-4bb4-931e-44e3995eaf48\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Token</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Sent</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>دانیلیان</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>،</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>مکرتچیان</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>،</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>هلقاتیان</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32880d50-19e5-4bb4-931e-44e3995eaf48')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32880d50-19e5-4bb4-931e-44e3995eaf48 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32880d50-19e5-4bb4-931e-44e3995eaf48');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          Token Tag Sent\n",
              "index                   \n",
              "10     دانیلیان   O    1\n",
              "11            ،   O    1\n",
              "12     مکرتچیان   O    1\n",
              "13            ،   O    1\n",
              "14     هلقاتیان   O    1"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "fa_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgNsqEv0aLbr"
      },
      "source": [
        "### Create tags table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nLdN_M1p_Wrx"
      },
      "outputs": [],
      "source": [
        "# Create list of name entity tags in train files\n",
        "tags_table = list(set(list (en_train.Tag) + list(fa_train.Tag)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph3srnLycIle"
      },
      "source": [
        "### Create Proper Input Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1U3Gkubw45l4"
      },
      "outputs": [],
      "source": [
        "# Create proper input files\n",
        "def write_file(en_df, fa_df, name, path='./data'):\n",
        "    # Get the first sentence. The parameter will be updated during execution of function and show the last processed sentence number.\n",
        "    last_sent = en_df.iloc[0].Sent\n",
        "\n",
        "    with open(f'{path}/{name}.txt', 'a') as writer:\n",
        "      # Write English (Token, Tag) pairs\n",
        "        for index, row in tqdm(en_df.iterrows(), desc = f'Writing English {name} file'):  \n",
        "            token, tag, current_sent = row\n",
        "\n",
        "            if (current_sent == last_sent):\n",
        "                writer.write(f\"{token}\\t{tag}\\n\")\n",
        "            else:\n",
        "                last_sent = current_sent\n",
        "                writer.write(f\"\\n\")\n",
        "                writer.write(f\"{token}\\t{tag}\\n\")\n",
        "\n",
        "        # Write Farsi (Token, Tag) pairs\n",
        "        last_row_df = fa_df.iloc[-1].Sent\n",
        "\n",
        "        for index, row in tqdm(fa_df.iterrows(), desc = f'Writing Farsi {name} file'):  \n",
        "            token, tag, current_sent = row\n",
        "\n",
        "            if current_sent!=last_row_df:\n",
        "                if (current_sent == last_sent):\n",
        "                    writer.write(f\"{token}\\t{tag}\\n\")\n",
        "\n",
        "                else:\n",
        "                    last_sent = current_sent\n",
        "                    writer.write(f\"\\n\")\n",
        "                    writer.write(f\"{token}\\t{tag}\\n\")\n",
        "            else:\n",
        "                # Last Sentence of file without newline char\n",
        "                writer.write(f\"\\n\")\n",
        "                writer.write(f\"{token}\\t{tag}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFt1JabRxHix",
        "outputId": "1f4262ce-974f-46c3-b1bb-dcb695416a93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Writing English train file: 178156it [00:12, 14254.70it/s]\n",
            "Writing Farsi train file: 195426it [00:13, 14438.42it/s]\n",
            "Writing English test file: 22681it [00:01, 14237.90it/s]\n",
            "Writing Farsi test file: 24682it [00:01, 13749.75it/s]\n",
            "Writing English val file: 52702it [00:03, 14226.80it/s]\n",
            "Writing Farsi val file: 58139it [00:04, 14204.54it/s]\n"
          ]
        }
      ],
      "source": [
        "# (Re)produce train test val files\n",
        "! rm -rf ./data/train.txt\n",
        "write_file(en_train, fa_train, 'train')\n",
        "! rm -rf ./data/test.txt\n",
        "write_file(en_test, fa_test, 'test')\n",
        "! rm -rf ./data/val.txt\n",
        "write_file(en_val, fa_val, 'val')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUJUUFa4UyF4"
      },
      "source": [
        "### Create Individual Test File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "OpbazCR7T6Le"
      },
      "outputs": [],
      "source": [
        "def write_individual_test(df, name, path='./data'):\n",
        "    # Get the first sentence. The parameter will be updated during execution of function and show the last processed sentence number.\n",
        "    last_sent = df.iloc[0].Sent\n",
        "\n",
        "    with open(f'{path}/{name}.txt', 'a') as writer:\n",
        "        last_row_df = df.iloc[-1].Sent\n",
        "\n",
        "        for index, row in tqdm(df.iterrows(), desc = f'Writing {name} file'):  \n",
        "            token, tag, current_sent = row\n",
        "\n",
        "            if current_sent!=last_row_df:\n",
        "                if (current_sent == last_sent):\n",
        "                    writer.write(f\"{token}\\t{tag}\\n\")\n",
        "\n",
        "                else:\n",
        "                    last_sent = current_sent\n",
        "                    writer.write(f\"\\n\")\n",
        "                    writer.write(f\"{token}\\t{tag}\\n\")\n",
        "            else:\n",
        "                # Last Sentence of file without newline char\n",
        "                writer.write(f\"\\n\")\n",
        "                writer.write(f\"{token}\\t{tag}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0d5kZFlU7ql",
        "outputId": "7aec1c05-e282-4c0d-c159-60ae6842b464"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Writing fa_test file: 24682it [00:01, 14056.93it/s]\n",
            "Writing en_test file: 22681it [00:01, 14433.86it/s]\n"
          ]
        }
      ],
      "source": [
        "! rm -rf ./data/fa_test.txt\n",
        "write_individual_test(fa_test,'fa_test')\n",
        "\n",
        "! rm -rf ./data/en_test.txt\n",
        "write_individual_test(en_test,'en_test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9ASUZ2n2aR2"
      },
      "source": [
        "## XLM-Roberta "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs5yGEFN2gHP"
      },
      "source": [
        "### TokenFromSubtoken\n",
        "- Code adapted from https://github.com/deepmipt/DeepPavlov/blob/master/deeppavlov/models/torch_bert/torch_transformers_sequence_tagger.py\n",
        "- DeepPavlov is an popular open source library for deep learning end-to-end dialog systems and chatbots.\n",
        "- Licensed under the Apache License, Version 2.0 (the \"License\");\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "MlP1uKJ9T8e4"
      },
      "outputs": [],
      "source": [
        "class TokenFromSubtoken(torch.nn.Module):\n",
        "\n",
        "    def forward(self, units: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\" Assemble token level units from subtoken level units\n",
        "        Args:\n",
        "            units: torch.Tensor of shape [batch_size, SUBTOKEN_seq_length, n_features]\n",
        "            mask: mask of token beginnings. For example: for tokens\n",
        "                    [[``[CLS]`` ``My``, ``capybara``, ``[SEP]``],\n",
        "                    [``[CLS]`` ``Your``, ``aar``, ``##dvark``, ``is``, ``awesome``, ``[SEP]``]]\n",
        "                the mask will be\n",
        "                    [[0, 1, 1, 0, 0, 0, 0],\n",
        "                    [0, 1, 1, 0, 1, 1, 0]]\n",
        "        Returns:\n",
        "            word_level_units: Units assembled from ones in the mask. For the\n",
        "                example above this units will correspond to the following\n",
        "                    [[``My``, ``capybara``],\n",
        "                    [``Your`, ``aar``, ``is``, ``awesome``,]]\n",
        "                the shape of this tensor will be [batch_size, TOKEN_seq_length, n_features]\n",
        "        \"\"\"\n",
        "        \n",
        "        device = units.device\n",
        "        nf_int = units.size()[-1]\n",
        "        batch_size = units.size()[0]\n",
        "\n",
        "        # number of TOKENS in each sentence\n",
        "        token_seq_lengths = torch.sum(mask, 1).to(torch.int64)\n",
        "        # number of words\n",
        "        n_words = torch.sum(token_seq_lengths)\n",
        "        # max token seq len\n",
        "        max_token_seq_len = torch.max(token_seq_lengths)\n",
        "\n",
        "        idxs = torch.stack(torch.nonzero(mask, as_tuple=True), dim=1)\n",
        "        # padding is for computing change from one sample to another in the batch\n",
        "        sample_ids_in_batch = torch.nn.functional.pad(input=idxs[:, 0], pad=[1, 0])\n",
        "        \n",
        "        a = (~torch.eq(sample_ids_in_batch[1:], sample_ids_in_batch[:-1])).to(torch.int64)\n",
        "        \n",
        "        # transforming sample start masks to the sample starts themselves\n",
        "        q = a * torch.arange(n_words, device=device).to(torch.int64)\n",
        "        count_to_substract = torch.nn.functional.pad(torch.masked_select(q, q.to(torch.bool)), [1, 0])\n",
        "\n",
        "        new_word_indices = torch.arange(n_words, device=device).to(torch.int64) - count_to_substract[torch.cumsum(a, 0)]\n",
        "        \n",
        "        n_total_word_elements = max_token_seq_len*torch.ones_like(token_seq_lengths, device=device).sum()\n",
        "        word_indices_flat = (idxs[:, 0] * max_token_seq_len + new_word_indices).to(torch.int64)\n",
        "        #x_mask = torch.sum(torch.nn.functional.one_hot(word_indices_flat, n_total_word_elements), 0)\n",
        "        #x_mask = x_mask.to(torch.bool)\n",
        "        x_mask = torch.zeros(n_total_word_elements, dtype=torch.bool, device=device)\n",
        "        x_mask[word_indices_flat] = torch.ones_like(word_indices_flat, device=device, dtype=torch.bool)\n",
        "        # to get absolute indices we add max_token_seq_len:\n",
        "        # idxs[:, 0] * max_token_seq_len -> [0, 0, 0, 1, 1, 2] * 2 = [0, 0, 0, 3, 3, 6]\n",
        "        # word_indices_flat -> [0, 0, 0, 3, 3, 6] + [0, 1, 2, 0, 1, 0] = [0, 1, 2, 3, 4, 6]\n",
        "        # total number of words in the batch (including paddings)\n",
        "        # batch_size * max_token_seq_len -> 3 * 3 = 9\n",
        "        # tf.one_hot(...) ->\n",
        "        # [[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
        "        #  [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
        "        #  [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
        "        #  [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
        "        #  [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
        "        #  [0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
        "        #  x_mask -> [1, 1, 1, 1, 1, 0, 1, 0, 0]\n",
        "        nonword_indices_flat = (~x_mask).nonzero().squeeze(-1)\n",
        "\n",
        "        # get a sequence of units corresponding to the start subtokens of the words\n",
        "        # size: [n_words, n_features]\n",
        "        \n",
        "        elements = units[mask.bool()]\n",
        "\n",
        "        # prepare zeros for paddings\n",
        "        # size: [batch_size * TOKEN_seq_length - n_words, n_features]\n",
        "        paddings = torch.zeros_like(nonword_indices_flat, dtype=elements.dtype).unsqueeze(-1).repeat(1,nf_int).to(device)\n",
        "\n",
        "        # tensor_flat -> [x, x, x, x, x, 0, x, 0, 0]\n",
        "        tensor_flat_unordered = torch.cat([elements, paddings])\n",
        "        _, order_idx = torch.sort(torch.cat([word_indices_flat, nonword_indices_flat]))\n",
        "        tensor_flat = tensor_flat_unordered[order_idx]\n",
        "\n",
        "        tensor = torch.reshape(tensor_flat, (-1, max_token_seq_len, nf_int))\n",
        "        # tensor -> [[x, x, x],\n",
        "        #            [x, x, 0],\n",
        "        #            [x, 0, 0]]\n",
        "\n",
        "        return tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2We9RK24f29"
      },
      "source": [
        "### Conditional Random Field \n",
        "- Code adopted form torchcrf library (https://pytorch-crf.readthedocs.io/en/stable/)\n",
        "- we override veiterbi decoder in order to make it compatible with our code "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "DjXultXaUj-t"
      },
      "outputs": [],
      "source": [
        "class CRF(SUPERCRF):\n",
        "\n",
        "    # override veiterbi decoder in order to make it compatible with our code \n",
        "    def _viterbi_decode(self, emissions: torch.FloatTensor,\n",
        "                        mask: torch.ByteTensor) -> List[List[int]]:\n",
        "        # emissions: (seq_length, batch_size, num_tags)\n",
        "        # mask: (seq_length, batch_size)\n",
        "        assert emissions.dim() == 3 and mask.dim() == 2\n",
        "        assert emissions.shape[:2] == mask.shape\n",
        "        assert emissions.size(2) == self.num_tags\n",
        "        assert mask[0].all()\n",
        "\n",
        "        seq_length, batch_size = mask.shape\n",
        "\n",
        "        # Start transition and first emission\n",
        "        # shape: (batch_size, num_tags)\n",
        "        score = self.start_transitions + emissions[0]\n",
        "        history = []\n",
        "\n",
        "        # score is a tensor of size (batch_size, num_tags) where for every batch,\n",
        "        # value at column j stores the score of the best tag sequence so far that ends\n",
        "        # with tag j\n",
        "        # history saves where the best tags candidate transitioned from; this is used\n",
        "        # when we trace back the best tag sequence\n",
        "\n",
        "        # Viterbi algorithm recursive case: we compute the score of the best tag sequence\n",
        "        # for every possible next tag\n",
        "        for i in range(1, seq_length):\n",
        "            # Broadcast viterbi score for every possible next tag\n",
        "            # shape: (batch_size, num_tags, 1)\n",
        "            broadcast_score = score.unsqueeze(2)\n",
        "\n",
        "            # Broadcast emission score for every possible current tag\n",
        "            # shape: (batch_size, 1, num_tags)\n",
        "            broadcast_emission = emissions[i].unsqueeze(1)\n",
        "\n",
        "            # Compute the score tensor of size (batch_size, num_tags, num_tags) where\n",
        "            # for each sample, entry at row i and column j stores the score of the best\n",
        "            # tag sequence so far that ends with transitioning from tag i to tag j and emitting\n",
        "            # shape: (batch_size, num_tags, num_tags)\n",
        "            next_score = broadcast_score + self.transitions + broadcast_emission\n",
        "\n",
        "            # Find the maximum score over all possible current tag\n",
        "            # shape: (batch_size, num_tags)\n",
        "            next_score, indices = next_score.max(dim=1)\n",
        "\n",
        "            # Set score to the next score if this timestep is valid (mask == 1)\n",
        "            # and save the index that produces the next score\n",
        "            # shape: (batch_size, num_tags)\n",
        "            score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
        "            history.append(indices)\n",
        "\n",
        "        history = torch.stack(history, dim=0)\n",
        "\n",
        "        # End transition score\n",
        "        # shape: (batch_size, num_tags)\n",
        "        score += self.end_transitions\n",
        "\n",
        "        # Now, compute the best path for each sample\n",
        "\n",
        "        # shape: (batch_size,)\n",
        "        seq_ends = mask.long().sum(dim=0) - 1\n",
        "        best_tags_list = []\n",
        "\n",
        "        for idx in range(batch_size):\n",
        "            # Find the tag which maximizes the score at the last timestep; this is our best tag\n",
        "            # for the last timestep\n",
        "            _, best_last_tag = score[idx].max(dim=0)\n",
        "            best_tags = [best_last_tag]\n",
        "\n",
        "            # We trace back where the best last tag comes from, append that to our best tag\n",
        "            # sequence, and trace it back again, and so on\n",
        "            for i, hist in enumerate(torch.flip(history[:seq_ends[idx]], dims=(0,))):\n",
        "                best_last_tag = hist[idx][best_tags[-1]]\n",
        "                best_tags.append(best_last_tag)\n",
        "\n",
        "            best_tags = torch.stack(best_tags, dim=0)\n",
        "\n",
        "            # Reverse the order because we start from the last timestep\n",
        "            best_tags_list.append(torch.flip(best_tags, dims=(0,)))\n",
        "\n",
        "        best_tags_list = nn.utils.rnn.pad_sequence(best_tags_list, batch_first=True, padding_value=0)\n",
        "\n",
        "        return best_tags_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KdozEy46dT4"
      },
      "source": [
        "### CRFLayer \n",
        "- Forward: decide output logits basaed on backbone network  \n",
        "- Decode: decode based on CRF weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "JNBE1vxOUJCe"
      },
      "outputs": [],
      "source": [
        "class CRFLayer(nn.Module):\n",
        "    def __init__(self, embedding_size, n_labels):\n",
        "\n",
        "        super(CRFLayer, self).__init__()\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.output_dense = nn.Linear(embedding_size,n_labels)\n",
        "        self.crf = CRF(n_labels, batch_first=True)\n",
        "        self.token_from_subtoken = TokenFromSubtoken()\n",
        "\n",
        "    # Forward: decide output logits basaed on backbone network  \n",
        "    def forward(self, embedding, mask):\n",
        "        logits = self.output_dense(self.dropout(embedding))\n",
        "        logits = self.token_from_subtoken(logits, mask)\n",
        "        pad_mask = self.token_from_subtoken(mask.unsqueeze(-1), mask).squeeze(-1).bool()\n",
        "        return logits, pad_mask\n",
        "\n",
        "    # Decode: decode based on CRF weights \n",
        "    def decode(self, logits, pad_mask):\n",
        "        return self.crf.decode(logits, pad_mask)\n",
        "\n",
        "    # Evaluation Loss: calculate mean log likelihood of CRF layer\n",
        "    def eval_loss(self, logits, targets, pad_mask):\n",
        "        mean_log_likelihood = self.crf(logits, targets, pad_mask, reduction='sum').mean()\n",
        "        return -mean_log_likelihood\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5ma5bWa7LaS"
      },
      "source": [
        "### NERModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "VE7L4jPKTmPp"
      },
      "outputs": [],
      "source": [
        "class NERModel(nn.Module):\n",
        "\n",
        "    def __init__(self, n_labels:int, roberta_path:str):\n",
        "        super(NERModel,self).__init__()\n",
        "        self.roberta = XLMRobertaModel.from_pretrained(roberta_path)\n",
        "        self.crf = CRFLayer(self.roberta.config.hidden_size, n_labels)\n",
        "\n",
        "    # Forward: pass embedings to CRF layer in order to evaluate logits from suboword sequence\n",
        "    def forward(self, \n",
        "                input_ids:torch.Tensor,\n",
        "                attention_mask:torch.Tensor,\n",
        "                token_type_ids:torch.Tensor,\n",
        "                mask:torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        embedding = self.roberta(input_ids=input_ids,\n",
        "                                 attention_mask=attention_mask,\n",
        "                                 token_type_ids=token_type_ids)[0]\n",
        "        logits, pad_mask = self.crf(embedding, mask)\n",
        "        return logits, pad_mask\n",
        "\n",
        "    # Disable Gradient and Predict with model\n",
        "    @torch.no_grad()\n",
        "    def predict(self, inputs:Tuple[torch.Tensor]) -> torch.Tensor:\n",
        "        input_ids, attention_mask, token_type_ids, mask = inputs\n",
        "        logits, pad_mask = self(input_ids, attention_mask, token_type_ids, mask)\n",
        "        decoded = self.crf.decode(logits, pad_mask)\n",
        "        return decoded, pad_mask\n",
        "\n",
        "    # Decode: pass to crf decoder and decode based on CRF weights \n",
        "    def decode(self, logits, pad_mask):\n",
        "        \"\"\"Decode logits using CRF weights \n",
        "        \"\"\"\n",
        "        return self.crf.decode(logits, pad_mask) \n",
        "\n",
        "    # Evaluation Loss: pass to crf eval_loss and calculate mean log likelihood of CRF layer\n",
        "    def eval_loss(self, logits, targets, pad_mask):\n",
        "        return self.crf.eval_loss(logits, targets, pad_mask)\n",
        "\n",
        "    # Determine number of layers to be fine-tuned (!freeze) \n",
        "    def freeze_roberta(self, n_freeze:int=6):\n",
        "        for param in self.roberta.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        for param in self.roberta.encoder.layer[n_freeze:].parameters():\n",
        "            param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBly2y20Kd_Q"
      },
      "source": [
        "### NERTokenizer\n",
        "- NLTK tokenizer along with XLMRobertaTokenizerFast tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "FtYHE7bFSg0X"
      },
      "outputs": [],
      "source": [
        "class NERTokenizer(object):\n",
        "\n",
        "    MAX_LEN=512\n",
        "    BATCH_LENGTH_LIMT = 380 # Max number of roberta tokens in one sentence.\n",
        "\n",
        "    # Modified version of http://stackoverflow.com/questions/36353125/nltk-regular-expression-tokenizer\n",
        "    PATTERN = r'''(?x)          # set flag to allow verbose regexps\n",
        "        (?:[A-Z]\\.)+        # abbreviations, e.g. U.S.A. or U.S.A # \n",
        "      | (?:\\d+\\.)           # numbers\n",
        "      | \\w+(?:[-.]\\w+)*     # words with optional internal hyphens\n",
        "      | \\$?\\d+(?:.\\d+)?%?   # currency and percentages, e.g. $12.40, 82%\n",
        "      | \\.\\.\\.              # ellipsis, and special chars below, includes ], [\n",
        "      | [-\\]\\[.,;\"'?():_`“”/°º‘’″…#$%()*+<>=@\\\\^_{}|~❑&§]\n",
        "    '''\n",
        "\n",
        "    def __init__(self, base_model:str, to_device:str='cpu'):\n",
        "        super(NERTokenizer,self).__init__()\n",
        "        self.roberta_tokenizer = XLMRobertaTokenizerFast.from_pretrained(base_model, do_lower_case=False)\n",
        "        self.to_device = to_device\n",
        "\n",
        "        self.word_tokenizer = RegexpTokenizer(self.PATTERN)\n",
        "        self.sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "    # tokenize batch of tokens\n",
        "    def tokenize_batch(self, inputs, pad_to = None) -> torch.Tensor:\n",
        "        batch = [inputs] if isinstance(inputs[0], str) else inputs\n",
        "\n",
        "        input_ids, attention_mask, token_type_ids, mask = [], [], [], []\n",
        "        for tokens in batch:\n",
        "            input_ids_tmp, attention_mask_tmp, token_type_ids_tmp, mask_tmp = self._tokenize_words(tokens)\n",
        "            input_ids.append(input_ids_tmp)\n",
        "            attention_mask.append(attention_mask_tmp)\n",
        "            token_type_ids.append(token_type_ids_tmp)\n",
        "            mask.append(mask_tmp)\n",
        "\n",
        "        input_ids = pad_sequence(input_ids, batch_first=True, padding_value=self.roberta_tokenizer.pad_token_id)\n",
        "        attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
        "        token_type_ids = pad_sequence(token_type_ids, batch_first=True, padding_value=0)\n",
        "        mask = pad_sequence(mask, batch_first=True, padding_value=0)\n",
        "\n",
        "        # truncate MAX_LEN\n",
        "        if input_ids.shape[-1]>self.MAX_LEN:\n",
        "            input_ids = input_ids[:,:,:self.MAX_LEN]\n",
        "            attention_mask = attention_mask[:,:,:self.MAX_LEN]\n",
        "            token_type_ids = token_type_ids[:,:,:self.MAX_LEN]\n",
        "            mask = mask[:,:,:self.MAX_LEN]\n",
        "        \n",
        "        # extend pad \n",
        "        elif pad_to is not None and pad_to>input_ids.shape[1]:\n",
        "            bs = input_ids.shape[0]\n",
        "            padlen = pad_to-input_ids.shape[1]\n",
        "            input_ids_append = torch.tensor([self.roberta_tokenizer.pad_token_id], dtype=torch.long).repeat([bs, padlen]).to(self.to_device)\n",
        "            input_ids = torch.cat([input_ids, input_ids_append], dim=-1)\n",
        "            attention_mask_append = torch.tensor([0], dtype=torch.long).repeat([bs, padlen]).to(self.to_device)\n",
        "            attention_mask = torch.cat([attention_mask, attention_mask_append], dim=-1)\n",
        "            token_type_ids_append = torch.tensor([0], dtype=torch.long).repeat([bs, padlen]).to(self.to_device)\n",
        "            token_type_ids = torch.cat([token_type_ids, token_type_ids_append], dim=-1)\n",
        "            mask_append = torch.tensor([0], dtype=torch.long).repeat([bs, padlen]).to(self.to_device)\n",
        "            mask = torch.cat([mask, mask_append], dim=-1)\n",
        "\n",
        "        # truncate pad\n",
        "        elif pad_to is not None and pad_to<input_ids.shape[1]:\n",
        "            input_ids = input_ids[:,:,:pad_to]\n",
        "            attention_mask = attention_mask[:,:,:pad_to]\n",
        "            token_type_ids = token_type_ids[:,:,:pad_to]\n",
        "            mask = mask[:,:,:pad_to]\n",
        "\n",
        "        if isinstance(inputs[0], str):\n",
        "            return input_ids[0], attention_mask[0], token_type_ids[0], mask[0]\n",
        "        else:\n",
        "            return input_ids, attention_mask, token_type_ids, mask\n",
        "\n",
        "    # tokenize list of words with roberta tokenizer\n",
        "    def _tokenize_words(self, words):\n",
        "        subtokenized = []\n",
        "        mask = []\n",
        "        for word in words:\n",
        "            subtokens = self.roberta_tokenizer.tokenize(word)\n",
        "            subtokenized+=subtokens\n",
        "            n_subtoken = len(subtokens)\n",
        "            if n_subtoken>=1:\n",
        "                mask = mask + [1] + [0]*(n_subtoken-1)\n",
        "\n",
        "        subtokenized = [self.roberta_tokenizer.cls_token] + subtokenized + [self.roberta_tokenizer.sep_token]\n",
        "        mask = [0] + mask + [0]\n",
        "\n",
        "        input_ids = torch.tensor(self.roberta_tokenizer.convert_tokens_to_ids(subtokenized), dtype=torch.long).to(self.to_device)\n",
        "        attention_mask = torch.ones(len(mask), dtype=torch.long).to(self.to_device)\n",
        "        token_type_ids = torch.zeros(len(mask), dtype=torch.long).to(self.to_device)\n",
        "        mask = torch.tensor(mask, dtype=torch.long).to(self.to_device)\n",
        "\n",
        "        return input_ids, attention_mask, token_type_ids, mask\n",
        "\n",
        "    # sent_to_token: yield each sentence token with positional span using nltk\n",
        "    def sent_to_token(self, raw_text):\n",
        "        for offset, ending in self.sent_tokenizer.span_tokenize(raw_text):\n",
        "            sub_text = raw_text[offset:ending]\n",
        "            words, spans = [], []\n",
        "            flush = False\n",
        "            total_subtoken = 0\n",
        "            for start, end in self.word_tokenizer.span_tokenize(sub_text):\n",
        "                flush = True\n",
        "                start += offset\n",
        "                end += offset\n",
        "                words.append(raw_text[start:end])\n",
        "                spans.append((start,end))\n",
        "                total_subtoken += len(self.roberta_tokenizer.tokenize(words[-1]))\n",
        "                if (total_subtoken > self.BATCH_LENGTH_LIMT): \n",
        "                    yield words[:-1],spans[:-1]\n",
        "                    spans = spans[len(spans)-1:]\n",
        "                    words = words[len(words)-1:]\n",
        "                    total_subtoken = sum([len(self.roberta_tokenizer.tokenize(word)) for word in words])\n",
        "                    flush = False\n",
        "\n",
        "            if flush and len(spans) > 0:\n",
        "                yield words,spans\n",
        "\n",
        "    # Extract (batch words span() from a raw sentence\n",
        "    def prepare_row_text(self, raw_text, batch_size=16):\n",
        "        words_list, spans_list = [], []\n",
        "        end_batch = False\n",
        "        for words, spans in self.sent_to_token(raw_text):\n",
        "            end_batch = True\n",
        "            words_list.append(words)\n",
        "            spans_list.append(spans)\n",
        "            if len(spans_list) >= batch_size:\n",
        "                input_ids, attention_mask, token_type_ids, mask = self.tokenize_batch(words_list)\n",
        "                yield (input_ids, attention_mask, token_type_ids, mask), words_list, spans_list\n",
        "                words_list, spans_list = [], []\n",
        "        if end_batch and len(words_list) > 0:\n",
        "            input_ids, attention_mask, token_type_ids, mask = self.tokenize_batch(words_list)\n",
        "            yield (input_ids, attention_mask, token_type_ids, mask), words_list, spans_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxw6sJOpLShZ"
      },
      "source": [
        "### NERDataset\n",
        "- Pythorch Compatible Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "AM8jQXF3F28x"
      },
      "outputs": [],
      "source": [
        "# Pytorch Dataset\n",
        "class NERDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_path:str, label_tags: List[str], base_model:str=\"xlm-roberta-base\", \n",
        "            default_label=0, max_length:int=512, to_device=\"cpu\"):\n",
        "        self.tokenizer = NERTokenizer(base_model=base_model, to_device=to_device)\n",
        "        self.label_tags = label_tags        \n",
        "        self.name_to_label = {x: i for i, x in enumerate(self.label_tags)}\n",
        "        self.default_label = default_label\n",
        "        self.max_length = max_length\n",
        "\n",
        "\n",
        "        # open file (train, test or val)\n",
        "        with open(data_path,'r') as f:\n",
        "            data_text = f.read()\n",
        "        self.data = []\n",
        "\n",
        "        # the loop notices the change of sentence with double newline \n",
        "        for sentence in filter(lambda x: len(x)>2, data_text.split('\\n\\n')):\n",
        "            sample = []\n",
        "            # each word laid in sepertaed lines\n",
        "            for wordline in sentence.split('\\n'):\n",
        "                if wordline=='':\n",
        "                    continue\n",
        "                # the word and label are seperated from each other with tab \n",
        "                word, label = wordline.split('\\t')\n",
        "                sample.append((word, label))\n",
        "            self.data.append(sample)\n",
        "\n",
        "    # len of dataset\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        words, labels = list(zip(*item))\n",
        "        \n",
        "        labels_idx = [self.name_to_label.get(x, self.default_label) for x in labels]  \n",
        "        y = torch.tensor(labels_idx, dtype=torch.long)\n",
        "        diff = self.max_length - y.shape[-1]\n",
        "        y = torch.nn.functional.pad(y, (0, diff), value=self.default_label)\n",
        "        X = self.tokenizer.tokenize_batch(list(words), pad_to=self.max_length)\n",
        "\n",
        "        return X, y "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shrgxfjlM2qw"
      },
      "source": [
        "### NERWrapper\n",
        "- Lightining Wrapper for NER Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "uLQUzO8qGRA-"
      },
      "outputs": [],
      "source": [
        "# Lightining Wrapper for NER Model\n",
        "\n",
        "class NERWrapper(pl.LightningModule):\n",
        "    def __init__(self,\n",
        "        learning_rate = 2e-5,\n",
        "        weight_decay = 0.0,\n",
        "        batch_size = 16,\n",
        "        freeze_layers = 8,\n",
        "        tags = tags_table,\n",
        "        train_path = \"./data/train.txt\",\n",
        "        val_path = \"./data/val.txt\",\n",
        "        test_path =\"./data/test.txt\",\n",
        "        pretrained_path = None,\n",
        "        *args, **kwargs\n",
        "    ):\n",
        "        \n",
        "        super(NERWrapper,self).__init__()\n",
        "        self.save_hyperparameters('learning_rate', 'weight_decay', 'batch_size')\n",
        "        self.tags, self.train_path, self.val_path, self.test_path = tags, train_path, val_path, test_path\n",
        "        self.model = NERModel(n_labels=len(self.tags), roberta_path=\"xlm-roberta-base\")\n",
        "\n",
        "        if pretrained_path is not None:\n",
        "            self.model.load_state_dict(torch.load(pretrained_path))\n",
        "        self.model.freeze_roberta(freeze_layers)\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        return self.model.forward(*args, **kwargs)\n",
        "\n",
        "    def _step(self, batch, batch_idx):\n",
        "        (input_ids, attention_mask, token_type_ids, mask), labels = batch\n",
        "        logits, pad_mask = self.model(input_ids, attention_mask, token_type_ids, mask)\n",
        "        labels = labels[:, :logits.shape[1]]\n",
        "        loss = self.model.eval_loss(logits, labels, pad_mask)\n",
        "        preds_tag_idx = self.model.decode(logits, pad_mask)\n",
        "        preds_tag = [[self.tags[start.item()] for m, start in zip(mask, sample) if m] for mask, sample in zip(pad_mask, preds_tag_idx)]\n",
        "        labels_tag = [[self.tags[start.item()] for m, start in zip(mask, sample) if m] for mask, sample in zip(pad_mask, labels)]\n",
        "        tensorboard_logs = {'batch_loss': loss}\n",
        "        for metric, value in tensorboard_logs.items():\n",
        "            self.log(metric, value, prog_bar=True)\n",
        "        return {'loss': loss, \"preds\": preds_tag, \"labels\": labels_tag}\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self._step(batch, batch_idx)['loss']\n",
        "\n",
        "    def validation_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        return self._step(batch, batch_idx)\n",
        "\n",
        "    def test_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        return self._step(batch, batch_idx)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        no_decay_keywords = [\"bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\n",
        "                \"params\": [p for n,p in self.model.named_parameters() if not any(nd in n for nd in no_decay_keywords)],\n",
        "                \"weight_decay_rate\": self.hparams.weight_decay,\n",
        "                \"lr\": self.hparams.learning_rate,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n,p in self.model.named_parameters() if any(nd in n for nd in no_decay_keywords)],\n",
        "                \"weight_decay_rate\": 0,\n",
        "                \"lr\": self.hparams.learning_rate,\n",
        "            }\n",
        "        ]\n",
        "        optimizer = torch.optim.AdamW(optimizer_grouped_parameters)\n",
        "        return optimizer\n",
        "\n",
        "    def _dataloader(self, path, shuffle=False):\n",
        "        dataset = NERDataset(path, label_tags = self.tags, default_label=0, to_device=self.device)\n",
        "        return DataLoader(dataset, drop_last=False, shuffle=shuffle, batch_size=self.hparams.batch_size, \n",
        "            worker_init_fn=np.random.seed(0))\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return self._dataloader(self.train_path, True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self._dataloader(self.val_path)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return self._dataloader(self.test_path)\n",
        "\n",
        "\n",
        "    def _epoch_end (self, outputs):\n",
        "        preds = sum([x['preds'] for x in outputs], [])\n",
        "        labels = sum([x['labels'] for x in outputs], [])\n",
        "        loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
        "        acc = accuracy_score(labels, preds)\n",
        "        precision = precision_score(labels, preds, mode='strict', scheme=IOB2, average='micro', zero_division=1)\n",
        "        recall = recall_score(labels, preds, mode='strict', scheme=IOB2, average='micro', zero_division=1)\n",
        "        f1 = f1_score(labels, preds, mode='strict', scheme=IOB2, average='micro', zero_division=1)\n",
        "        tensorboard_logs = {'loss': loss, 'acc': acc, 'precision': precision, 'recall': recall, 'f1': f1}\n",
        "        return tensorboard_logs\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        val_logs = self._epoch_end(outputs)\n",
        "        tensorboard_logs = {'val_loss': val_logs['loss'], 'val_accuracy': val_logs['acc'], 'val_precision': val_logs['precision'], 'val_recall': val_logs['recall'], 'val_F1': val_logs['f1']}\n",
        "        for metric, value in tensorboard_logs.items():\n",
        "            self.log(metric, value, prog_bar=True)\n",
        " \n",
        "    def test_epoch_end(self, outputs):\n",
        "        test_logs = self._epoch_end(outputs)\n",
        "        tensorboard_logs = {'test_loss': test_logs['loss'], 'test_accuracy': test_logs['acc'], 'test_precision': test_logs['precision'], 'test_recall': test_logs['recall'], 'test_F1': test_logs['f1']}\n",
        "        for metric, value in tensorboard_logs.items():\n",
        "            self.log(metric, value, prog_bar=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJQ8xMLaNUX_"
      },
      "source": [
        "### NER\n",
        "NER Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Q1UKVydicabm"
      },
      "outputs": [],
      "source": [
        "class NER(object):\n",
        "\n",
        "    def __init__(self, model_path, model_name = MODEL_NAME, tags = tags_table):\n",
        "        \n",
        "        self.tags = tags\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        roberta_path = \"xlm-roberta-base\"\n",
        "        self.model = NERModel(n_labels=len(self.tags), roberta_path=roberta_path).to(self.device)\n",
        "        state_dict = torch.load(os.path.join(model_path, model_name))\n",
        "        self.model.load_state_dict(state_dict, strict=False)\n",
        "        self.model.eval()\n",
        "        self.tokenizer = NERTokenizer(base_model=roberta_path, to_device=self.device)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def __call__(self, raw_text):\n",
        "\n",
        "        outputs_flat, spans_flat, entities = [], [], []\n",
        "        for batch, words, spans in self.tokenizer.prepare_row_text(raw_text):\n",
        "            output, pad_mask = self.model.predict(batch)\n",
        "            outputs_flat.extend(output[pad_mask.bool()].reshape(-1).tolist())\n",
        "            spans_flat += sum(spans, [])\n",
        "\n",
        "        for tag_idx,(start,end) in zip(outputs_flat,spans_flat):\n",
        "            tag = self.tags[tag_idx]\n",
        "            if tag != 'O':\n",
        "                entities.append({'Text': raw_text[start:end], 'Tag': tag})\n",
        "\n",
        "        return entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CsN8qC1Nfg8"
      },
      "source": [
        "## Train, and Test Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLaKu4s9OZZl"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "kS1vwDB2VQV3"
      },
      "outputs": [],
      "source": [
        "# train function \n",
        "def train_test(test_path):\n",
        "    plmodel = NERWrapper(test_path = test_path)\n",
        "    trainer = pl.Trainer(default_root_dir=CHECKPOINT_PATH, gpus=1, max_epochs=MAX_EPOCHS)\n",
        "    trainer.fit(plmodel)\n",
        "    result = trainer.test(plmodel)\n",
        "    print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617,
          "referenced_widgets": [
            "7917c55557e64f5a926ac23c20fb146d",
            "b24deb8ec7554825b75a5079a72dbc5a",
            "8fdce2e3a6ec494eb0180f72bf3e265b",
            "3bd1283962f34d41bc63b42d0d7a52c9",
            "253fbd1b8c6a4940ab0ed7d7f4e37033",
            "57ba815493a64473a130ffd1030ba335",
            "bf0ef87705d8407eb86de90076742166",
            "7b8ced5abf7e4e61b7dc852768e661c0",
            "7c79cb7c63a14d62b23ec4da1297f449",
            "74620e8d345a43bab0d40df409837f79",
            "e858beeaa6af4437b6157c8afee03009",
            "bf23f5d12d9747f3a68d91d484902843",
            "3dcdf2de7cc647a19d93551f3fa63357",
            "8cece315291f42debce8a68623cfd365",
            "0939d15a6250455aad048a86a34b07b4",
            "29ef9783ec3b4fb7a3f6e693eb7f0803",
            "dc92fedd613f476f9ee2308c00528f5b",
            "b80d7002ffb443f4af03f1fd287d7ee3",
            "973d0b3eeb1d4d8f982b7204072f371c",
            "82cb74501aa5434bb1b2841fd70b9d59",
            "d1d9227fd46046478a6c9099d889e66a",
            "4db907e1aa384b7a85d1f27621a43369",
            "80d2fb9de46442f3813926074f0ba572",
            "12be4f429457479795e516e4407a66cb",
            "e875664cdb1f4876a938dffa9288ec2d",
            "ef2242ad3f04478d91783a56529c70d2",
            "44fae33ab38a4847a05da6655dbf1348",
            "7cba5b9c02a34866802ac95435f74fd9",
            "9d8cef34cf6a4d3cbc14d2b1868df173",
            "c400c8346b2b43e0822b463220afb922",
            "4e86c54f24dd431aa84b194dd513b107",
            "f488f641d30d448595b74ac2dd9d0fb6",
            "a78e2e2195404499b212a4ad8a3c81e3",
            "18ba49a306f143a7bc23a8a949f71893",
            "090c7028cbd74bb59ebfc3a08365588c",
            "ae67d4237cc24f6a87ba173382c1b8ef",
            "66327d13171b49b0935ee08eca99a90b",
            "c0de83bd96d94753bcb3d7f725e76689",
            "1d5df61cfdda4e3fb31640083e47c788",
            "164fea2bb4d0480789755e56f4d9a7ab",
            "9542f3f37e544115b8cff198640c2c93",
            "3a64f794ff53465aae12524a817bb07b",
            "2804cf2d940f4a8897f8e272fed1f8ff",
            "5e9331bc3bf24bb1a02c26956727ca87",
            "de430e5ae99e45ec8f779bf9f792b0f1",
            "2c53ebd285884b82bd35c477c53d740f",
            "e3523074123f4b0fb8a5ed493832ac28",
            "ab6b5daad0c242f79e9d57f0569baa43",
            "473d1aed520d450989d5f3f0fcb5bb7f",
            "0e351aeaf4764ab5ab98ec27667f554a",
            "1f4c34c428d543ada64fa1646017d45f",
            "f67efac3c90841038ab3497b5fba7842",
            "7dab96b6edfa4273b0c7bb6f1d96336a",
            "c4fe5e3842254deaafd8ff154b75db30",
            "4750493803d6407a9c058a8dcb15f11d",
            "4bc139b750b94cecbbc3ff6d4c5632fa",
            "fc4b6f907da64a46b46dc11c81899e01",
            "d57283ca7dda412b84cfad5dd41f8d04",
            "cb7d0b4c6fbd450688537a6a1557814f",
            "447caa5b72b0406d97014e1a1c2b564e",
            "1e6b5c1dff7848828fe960d6c577979d",
            "9be86c07780d46cf9b03aad8e8c8c95a",
            "dcf5b7d860b34ca2bd2b2665646659bb",
            "13c45778a97348c78229e98d8185b8a3",
            "e140a34c5b624645997921460168126b",
            "d891b13019ab4e1892e4b6fed6cbcf44",
            "4ee7b7649ac849aba9dfccdadd99e3a3",
            "a168e2bdff4c400084583c512c4c6e52",
            "cec91830b38640bb9dbf30a622a8b4ff",
            "fdfac2510615401d9a41855fa16923b5",
            "e837cf23a90843bda1f6e3cae914c084",
            "686bbdf780904352a8b388724cc3cf5c",
            "fc23213ad6c94e929ae131b72b00073b",
            "71a9943e17c1402fb24d437611873080",
            "c43af00eac3347f194ab75ec2ad4f31d",
            "124d351f79f64c1c81ef74d17cd8f4d1",
            "9deeca17afb8471eaa1be12b00b4d199"
          ]
        },
        "id": "q54YuSzIWSBN",
        "outputId": "61e5a9a1-7c7c-4981-9a2c-bc76e58c8172"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7917c55557e64f5a926ac23c20fb146d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/512 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf23f5d12d9747f3a68d91d484902843",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type     | Params\n",
            "-----------------------------------\n",
            "0 | model | NERModel | 278 M \n",
            "-----------------------------------\n",
            "28.4 M    Trainable params\n",
            "249 M     Non-trainable params\n",
            "278 M     Total params\n",
            "1,112.215 Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80d2fb9de46442f3813926074f0ba572",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18ba49a306f143a7bc23a8a949f71893",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de430e5ae99e45ec8f779bf9f792b0f1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4bc139b750b94cecbbc3ff6d4c5632fa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ee7b7649ac849aba9dfccdadd99e3a3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# Train on both Fa and En and test on both En and Fa\n",
        "\n",
        "train_test (test_path = \"./data/test.txt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbRnXOvXN-mQ"
      },
      "source": [
        "### Save Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "C-nVeBB_OCrR"
      },
      "outputs": [],
      "source": [
        "# PATH of Last checkpoint\n",
        "\n",
        "CKPT_PATH = CHECKPOINT_PATH + \"/\" + \"lightning_logs/version_0/checkpoints/epoch=0-step=1338.ckpt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "sz4e7gCKN7d2"
      },
      "outputs": [],
      "source": [
        "def save_checkpint_to_pt(ckpt_path_file, model_path=MODEL_PATH, model_name=MODEL_NAME):\n",
        "    plmodule = NERWrapper()\n",
        "    plmodule.load_state_dict(torch.load(ckpt_path_file)['state_dict'])\n",
        "\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        os.makedirs(MODEL_PATH)\n",
        "    torch.save(plmodule.model.state_dict(), os.path.join(MODEL_PATH, MODEL_NAME))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "T9VvBA_WeRS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4304a119-df7a-4f45-dbf4-0ed1e2198711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Call save model\n",
        "save_checkpint_to_pt(ckpt_path_file=CKPT_PATH, model_path=MODEL_PATH, model_name=MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmyhSl6qPPqV"
      },
      "source": [
        "### Test with Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "uGF0w7aIYHOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46bd3cb6-7ecc-4bb7-86e3-439c7fcd4690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# del ner\n",
        "ner = NER(model_path = MODEL_PATH, model_name = MODEL_NAME, tags = tags_table) # Load pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "SyqtKUlSYgvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5febe497-820c-434f-ba25-a35561bc78da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Tag': 'B-CORP', 'Text': 'گوگل'}]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "text = \"\"\"علی به شرکت گوگل رفت\"\"\"\n",
        "result = ner(text)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plmodule = NERWrapper()\n",
        "plmodule.load_state_dict(torch.load(CKPT_PATH)['state_dict'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnEMxHPiK5QK",
        "outputId": "69dbc037-488b-4221-c196-47ddfd2d2a2f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plmodule.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FZwKESmLDBu",
        "outputId": "669775f4-bb87-49c4-f092-2aa60e6f6e35"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NERWrapper(\n",
              "  (model): NERModel(\n",
              "    (roberta): XLMRobertaModel(\n",
              "      (embeddings): RobertaEmbeddings(\n",
              "        (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "        (token_type_embeddings): Embedding(1, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): RobertaEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): RobertaPooler(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "    (crf): CRFLayer(\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (output_dense): Linear(in_features=768, out_features=13, bias=True)\n",
              "      (crf): CRF(num_tags=13)\n",
              "      (token_from_subtoken): TokenFromSubtoken()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(default_root_dir=CHECKPOINT_PATH, gpus=1, max_epochs=1)\n",
        "# trainer.fit(plmodule)\n",
        "result = trainer.test(plmodule)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283,
          "referenced_widgets": [
            "922fc6ef257b46f19a41b25565cacbff",
            "c125a9b450eb4e1e9d5782ccd24515b3",
            "d45fce9b7e214418891c6deb5e7d6577",
            "08bccb2449d949baaaa32258ce7f5533",
            "91c97aca3f9a4c909199c25aee4c4e17",
            "38ec172301194c4b8dcbf4ecbd9b04fa",
            "f77967ed55a34b97a9eaa333573bab48",
            "22046c7d799e4871916236a60670cd25",
            "bc1609a723b24a26bdd667d82a6dff4a",
            "a9fb63ae2d2340b886cf211c445ffca6",
            "2209ac2c41444a85bc05e8933db42f89"
          ]
        },
        "id": "mSJlo-vmLKNi",
        "outputId": "85b51c98-58d9-4563-a59d-99393a3b0c0e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "922fc6ef257b46f19a41b25565cacbff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'batch_loss': 62.05730438232422,\n",
            " 'test_F1': 0.6647171010807374,\n",
            " 'test_accuracy': 0.9269471764564514,\n",
            " 'test_loss': 61.80181884765625,\n",
            " 'test_precision': 0.7078256160303277,\n",
            " 'test_recall': 0.6265580057526366}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6_YlbnYlLpq6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Roberta_NER.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7917c55557e64f5a926ac23c20fb146d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b24deb8ec7554825b75a5079a72dbc5a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8fdce2e3a6ec494eb0180f72bf3e265b",
              "IPY_MODEL_3bd1283962f34d41bc63b42d0d7a52c9",
              "IPY_MODEL_253fbd1b8c6a4940ab0ed7d7f4e37033"
            ]
          }
        },
        "b24deb8ec7554825b75a5079a72dbc5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8fdce2e3a6ec494eb0180f72bf3e265b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_57ba815493a64473a130ffd1030ba335",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf0ef87705d8407eb86de90076742166"
          }
        },
        "3bd1283962f34d41bc63b42d0d7a52c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7b8ced5abf7e4e61b7dc852768e661c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 512,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 512,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c79cb7c63a14d62b23ec4da1297f449"
          }
        },
        "253fbd1b8c6a4940ab0ed7d7f4e37033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_74620e8d345a43bab0d40df409837f79",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 512/512 [00:00&lt;00:00, 13.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e858beeaa6af4437b6157c8afee03009"
          }
        },
        "57ba815493a64473a130ffd1030ba335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf0ef87705d8407eb86de90076742166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b8ced5abf7e4e61b7dc852768e661c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c79cb7c63a14d62b23ec4da1297f449": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74620e8d345a43bab0d40df409837f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e858beeaa6af4437b6157c8afee03009": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf23f5d12d9747f3a68d91d484902843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3dcdf2de7cc647a19d93551f3fa63357",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8cece315291f42debce8a68623cfd365",
              "IPY_MODEL_0939d15a6250455aad048a86a34b07b4",
              "IPY_MODEL_29ef9783ec3b4fb7a3f6e693eb7f0803"
            ]
          }
        },
        "3dcdf2de7cc647a19d93551f3fa63357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8cece315291f42debce8a68623cfd365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dc92fedd613f476f9ee2308c00528f5b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b80d7002ffb443f4af03f1fd287d7ee3"
          }
        },
        "0939d15a6250455aad048a86a34b07b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_973d0b3eeb1d4d8f982b7204072f371c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1115590446,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1115590446,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_82cb74501aa5434bb1b2841fd70b9d59"
          }
        },
        "29ef9783ec3b4fb7a3f6e693eb7f0803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d1d9227fd46046478a6c9099d889e66a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04G/1.04G [00:33&lt;00:00, 34.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4db907e1aa384b7a85d1f27621a43369"
          }
        },
        "dc92fedd613f476f9ee2308c00528f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b80d7002ffb443f4af03f1fd287d7ee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "973d0b3eeb1d4d8f982b7204072f371c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "82cb74501aa5434bb1b2841fd70b9d59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1d9227fd46046478a6c9099d889e66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4db907e1aa384b7a85d1f27621a43369": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80d2fb9de46442f3813926074f0ba572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_12be4f429457479795e516e4407a66cb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e875664cdb1f4876a938dffa9288ec2d",
              "IPY_MODEL_ef2242ad3f04478d91783a56529c70d2",
              "IPY_MODEL_44fae33ab38a4847a05da6655dbf1348"
            ]
          }
        },
        "12be4f429457479795e516e4407a66cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "e875664cdb1f4876a938dffa9288ec2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7cba5b9c02a34866802ac95435f74fd9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validation sanity check: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d8cef34cf6a4d3cbc14d2b1868df173"
          }
        },
        "ef2242ad3f04478d91783a56529c70d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c400c8346b2b43e0822b463220afb922",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e86c54f24dd431aa84b194dd513b107"
          }
        },
        "44fae33ab38a4847a05da6655dbf1348": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f488f641d30d448595b74ac2dd9d0fb6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:02&lt;00:00,  1.27s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a78e2e2195404499b212a4ad8a3c81e3"
          }
        },
        "7cba5b9c02a34866802ac95435f74fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d8cef34cf6a4d3cbc14d2b1868df173": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c400c8346b2b43e0822b463220afb922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e86c54f24dd431aa84b194dd513b107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f488f641d30d448595b74ac2dd9d0fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a78e2e2195404499b212a4ad8a3c81e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18ba49a306f143a7bc23a8a949f71893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_090c7028cbd74bb59ebfc3a08365588c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ae67d4237cc24f6a87ba173382c1b8ef",
              "IPY_MODEL_66327d13171b49b0935ee08eca99a90b",
              "IPY_MODEL_c0de83bd96d94753bcb3d7f725e76689"
            ]
          }
        },
        "090c7028cbd74bb59ebfc3a08365588c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae67d4237cc24f6a87ba173382c1b8ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1d5df61cfdda4e3fb31640083e47c788",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_164fea2bb4d0480789755e56f4d9a7ab"
          }
        },
        "66327d13171b49b0935ee08eca99a90b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9542f3f37e544115b8cff198640c2c93",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a64f794ff53465aae12524a817bb07b"
          }
        },
        "c0de83bd96d94753bcb3d7f725e76689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2804cf2d940f4a8897f8e272fed1f8ff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.83M/4.83M [00:00&lt;00:00, 12.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e9331bc3bf24bb1a02c26956727ca87"
          }
        },
        "1d5df61cfdda4e3fb31640083e47c788": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "164fea2bb4d0480789755e56f4d9a7ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9542f3f37e544115b8cff198640c2c93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a64f794ff53465aae12524a817bb07b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2804cf2d940f4a8897f8e272fed1f8ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e9331bc3bf24bb1a02c26956727ca87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de430e5ae99e45ec8f779bf9f792b0f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2c53ebd285884b82bd35c477c53d740f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e3523074123f4b0fb8a5ed493832ac28",
              "IPY_MODEL_ab6b5daad0c242f79e9d57f0569baa43",
              "IPY_MODEL_473d1aed520d450989d5f3f0fcb5bb7f"
            ]
          }
        },
        "2c53ebd285884b82bd35c477c53d740f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3523074123f4b0fb8a5ed493832ac28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0e351aeaf4764ab5ab98ec27667f554a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f4c34c428d543ada64fa1646017d45f"
          }
        },
        "ab6b5daad0c242f79e9d57f0569baa43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f67efac3c90841038ab3497b5fba7842",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9096718,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9096718,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7dab96b6edfa4273b0c7bb6f1d96336a"
          }
        },
        "473d1aed520d450989d5f3f0fcb5bb7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c4fe5e3842254deaafd8ff154b75db30",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8.68M/8.68M [00:01&lt;00:00, 4.21MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4750493803d6407a9c058a8dcb15f11d"
          }
        },
        "0e351aeaf4764ab5ab98ec27667f554a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f4c34c428d543ada64fa1646017d45f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f67efac3c90841038ab3497b5fba7842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7dab96b6edfa4273b0c7bb6f1d96336a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4fe5e3842254deaafd8ff154b75db30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4750493803d6407a9c058a8dcb15f11d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4bc139b750b94cecbbc3ff6d4c5632fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fc4b6f907da64a46b46dc11c81899e01",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d57283ca7dda412b84cfad5dd41f8d04",
              "IPY_MODEL_cb7d0b4c6fbd450688537a6a1557814f",
              "IPY_MODEL_447caa5b72b0406d97014e1a1c2b564e"
            ]
          }
        },
        "fc4b6f907da64a46b46dc11c81899e01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "d57283ca7dda412b84cfad5dd41f8d04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1e6b5c1dff7848828fe960d6c577979d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Epoch 1:  23%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9be86c07780d46cf9b03aad8e8c8c95a"
          }
        },
        "cb7d0b4c6fbd450688537a6a1557814f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dcf5b7d860b34ca2bd2b2665646659bb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1741,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13c45778a97348c78229e98d8185b8a3"
          }
        },
        "447caa5b72b0406d97014e1a1c2b564e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e140a34c5b624645997921460168126b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 400/1741 [11:25&lt;38:16,  1.71s/it, loss=62.6, v_num=0, batch_loss=38.90, val_loss=60.70, val_accuracy=0.925, val_precision=0.642, val_recall=0.676, val_F1=0.659]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d891b13019ab4e1892e4b6fed6cbcf44"
          }
        },
        "1e6b5c1dff7848828fe960d6c577979d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9be86c07780d46cf9b03aad8e8c8c95a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dcf5b7d860b34ca2bd2b2665646659bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13c45778a97348c78229e98d8185b8a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e140a34c5b624645997921460168126b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d891b13019ab4e1892e4b6fed6cbcf44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ee7b7649ac849aba9dfccdadd99e3a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a168e2bdff4c400084583c512c4c6e52",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cec91830b38640bb9dbf30a622a8b4ff",
              "IPY_MODEL_fdfac2510615401d9a41855fa16923b5",
              "IPY_MODEL_e837cf23a90843bda1f6e3cae914c084"
            ]
          }
        },
        "a168e2bdff4c400084583c512c4c6e52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "cec91830b38640bb9dbf30a622a8b4ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_686bbdf780904352a8b388724cc3cf5c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validating: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc23213ad6c94e929ae131b72b00073b"
          }
        },
        "fdfac2510615401d9a41855fa16923b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_71a9943e17c1402fb24d437611873080",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 402,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 402,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c43af00eac3347f194ab75ec2ad4f31d"
          }
        },
        "e837cf23a90843bda1f6e3cae914c084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_124d351f79f64c1c81ef74d17cd8f4d1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 402/402 [07:19&lt;00:00,  1.15s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9deeca17afb8471eaa1be12b00b4d199"
          }
        },
        "686bbdf780904352a8b388724cc3cf5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc23213ad6c94e929ae131b72b00073b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71a9943e17c1402fb24d437611873080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c43af00eac3347f194ab75ec2ad4f31d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "124d351f79f64c1c81ef74d17cd8f4d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9deeca17afb8471eaa1be12b00b4d199": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "922fc6ef257b46f19a41b25565cacbff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c125a9b450eb4e1e9d5782ccd24515b3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d45fce9b7e214418891c6deb5e7d6577",
              "IPY_MODEL_08bccb2449d949baaaa32258ce7f5533",
              "IPY_MODEL_91c97aca3f9a4c909199c25aee4c4e17"
            ]
          }
        },
        "c125a9b450eb4e1e9d5782ccd24515b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "d45fce9b7e214418891c6deb5e7d6577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_38ec172301194c4b8dcbf4ecbd9b04fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Testing: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f77967ed55a34b97a9eaa333573bab48"
          }
        },
        "08bccb2449d949baaaa32258ce7f5533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_22046c7d799e4871916236a60670cd25",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc1609a723b24a26bdd667d82a6dff4a"
          }
        },
        "91c97aca3f9a4c909199c25aee4c4e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a9fb63ae2d2340b886cf211c445ffca6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 173/173 [03:10&lt;00:00,  1.11s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2209ac2c41444a85bc05e8933db42f89"
          }
        },
        "38ec172301194c4b8dcbf4ecbd9b04fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f77967ed55a34b97a9eaa333573bab48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22046c7d799e4871916236a60670cd25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc1609a723b24a26bdd667d82a6dff4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9fb63ae2d2340b886cf211c445ffca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2209ac2c41444a85bc05e8933db42f89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}